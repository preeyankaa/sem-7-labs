{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries\n"
      ],
      "metadata": {
        "id": "8W4kt1QVL4Rh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import nltk, re\n",
        "\n",
        "nltk.download('punkt', download_dir='/root/nltk_data')\n",
        "nltk.download('stopwords', download_dir='/root/nltk_data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x80edyOXL9-p",
        "outputId": "34fb8e13-5980-40e7-eb30-1675bb0393ba"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample data\n"
      ],
      "metadata": {
        "id": "xxANcI6yMdSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    \"NLP is amazing!\",\n",
        "    \"Text preprocessing is important for NLP.\",\n",
        "    \"TF-IDF and BoW are useful.\",\n",
        "    \"Text data needs to be cleaned before modeling.\"\n",
        "]"
      ],
      "metadata": {
        "id": "9CsVGKjWMcSF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess text"
      ],
      "metadata": {
        "id": "T6lV2YbYMkKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    text = text.lower()                          # Lowercase\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)         # Remove punctuation\n",
        "    words = nltk.word_tokenize(text)             # Tokenize\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [w for w in words if w not in stop_words]\n",
        "    stemmer = PorterStemmer()\n",
        "    words = [stemmer.stem(w) for w in words]     # Stemming\n",
        "    # print(' '.join(words))\n",
        "    return ' '.join(words)\n",
        "\n",
        "\n",
        "cleaned_texts = [preprocess(t) for t in texts]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmzWYfI9Mjci",
        "outputId": "780cf625-b939-4cf9-ba26-9632fb8b07f4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nlp amaz\n",
            "text preprocess import nlp\n",
            "tfidf bow use\n",
            "text data need clean model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Extraction (BoW & TF-IDF)"
      ],
      "metadata": {
        "id": "UC7FNEbYNltR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag-of-Words\n",
        "bow = CountVectorizer()\n",
        "bow_matrix = bow.fit_transform(cleaned_texts)\n",
        "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=bow.get_feature_names_out())\n",
        "\n",
        "# TF-IDF\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf.fit_transform(cleaned_texts)\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n"
      ],
      "metadata": {
        "id": "6tRcoZq2NlFh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display & Compare"
      ],
      "metadata": {
        "id": "AC9i5qTPNu05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" Bag-of-Words Matrix:\")\n",
        "print(bow_df)\n",
        "\n",
        "print(\"\\n TF-IDF Matrix:\")\n",
        "print(tfidf_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcceGqhNNw0p",
        "outputId": "d84fd406-0d5a-4cca-d7ea-a6a0c72b1709"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¢ Bag-of-Words Matrix:\n",
            "   amaz  bow  clean  data  import  model  need  nlp  preprocess  text  tfidf  \\\n",
            "0     1    0      0     0       0      0     0    1           0     0      0   \n",
            "1     0    0      0     0       1      0     0    1           1     1      0   \n",
            "2     0    1      0     0       0      0     0    0           0     0      1   \n",
            "3     0    0      1     1       0      1     1    0           0     1      0   \n",
            "\n",
            "   use  \n",
            "0    0  \n",
            "1    0  \n",
            "2    1  \n",
            "3    0  \n",
            "\n",
            "ðŸŒŸ TF-IDF Matrix:\n",
            "       amaz      bow     clean      data    import     model      need  \\\n",
            "0  0.785288  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "1  0.000000  0.00000  0.000000  0.000000  0.555283  0.000000  0.000000   \n",
            "2  0.000000  0.57735  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "3  0.000000  0.00000  0.465162  0.465162  0.000000  0.465162  0.465162   \n",
            "\n",
            "        nlp  preprocess      text    tfidf      use  \n",
            "0  0.619130    0.000000  0.000000  0.00000  0.00000  \n",
            "1  0.437791    0.555283  0.437791  0.00000  0.00000  \n",
            "2  0.000000    0.000000  0.000000  0.57735  0.57735  \n",
            "3  0.000000    0.000000  0.366739  0.00000  0.00000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Comparison"
      ],
      "metadata": {
        "id": "yiiwGTjCRID5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare word \"nlp\" (if present in both)\n",
        "print(\"\\nCompare 'nlp' in BoW vs TF-IDF:\")\n",
        "print(\"BoW:\", bow_df['nlp'].values if 'nlp' in bow_df else 'Not present')\n",
        "print(\"TF-IDF:\", tfidf_df['nlp'].values if 'nlp' in tfidf_df else 'Not present')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2RVMjFsRIrH",
        "outputId": "3633c2b6-06da-451d-c2f1-189469036a9f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Compare 'nlp' in BoW vs TF-IDF:\n",
            "BoW: [1 1 0 0]\n",
            "TF-IDF: [0.6191303  0.43779123 0.         0.        ]\n"
          ]
        }
      ]
    }
  ]
}